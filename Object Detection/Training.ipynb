{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1d4a46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MSCOCO import MSCOCO\n",
    "from utils import *\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "32c31ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_classes, coco_object_categories = load_coco_classes('./mscoco_labels.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03193931",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = '../../../Datasets/MS COCO'\n",
    "json_annotations = './json files/train_annotation.json'\n",
    "target_classes = ['__bgr__', 'person', 'car']\n",
    "\n",
    "train_interface_params = {\n",
    "    'root_path': root_path,\n",
    "    'list_of_classes': coco_classes,\n",
    "    'target_classes': target_classes,\n",
    "    'stage': 'train', \n",
    "    'annotation_json_path': json_annotations\n",
    "}\n",
    "\n",
    "train_interface = MSCOCO(**train_interface_params)\n",
    "\n",
    "val_interface_params = {\n",
    "    'root_path': root_path,\n",
    "    'list_of_classes': coco_classes,\n",
    "    'target_classes': target_classes,\n",
    "    'stage': 'train', \n",
    "    'annotation_json_path': json_annotations\n",
    "}\n",
    "\n",
    "val_interface = MSCOCO(**val_interface_params)\n",
    "\n",
    "\n",
    "train_dataloader_args = {'batch_size':1, 'shuffle':True}\n",
    "train_dataloader = data.DataLoader(train_interface, **train_dataloader_args)\n",
    "\n",
    "val_dataloader_args = {'batch_size':1, 'shuffle':False}\n",
    "val_dataloader = data.DataLoader(val_interface, **val_dataloader_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d412957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "\n",
    "print(f'Available device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eadef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "faster_rcnn = load_faster_rcnn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9d677fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_pars = {'lr':1e-5, 'weight_decay':1e-3}\n",
    "optimizer = torch.optim.Adam(list(faster_rcnn.parameters()),**optimizer_pars)\n",
    "total_epoch = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e02b2160",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Khaliladib\\anaconda3\\envs\\ailab\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4115957021713257\n",
      "1.3172643184661865\n",
      "1.0032185316085815\n",
      "1.2356420755386353\n",
      "0.7537310123443604\n",
      "0.5540332794189453\n",
      "0.8387885689735413\n",
      "1.0503934621810913\n",
      "4.747684001922607\n",
      "1.0005332231521606\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_19236\\3518470168.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;34m\"load_checkpoint\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m }\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mtraining_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mtraining_param\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\City University of London\\MSc Artificial intelligence\\Term 2\\INM705 Deep Learning for Image Analysis\\Coursework\\CW\\Object Detection\\utils.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(model, train_loader, val_loader, optimizer, epochs, device, checkpoint_path, load_checkpoint)\u001b[0m\n\u001b[0;32m    118\u001b[0m                 \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m                 \u001b[0mtrain_epoch_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtotal_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m             \u001b[0mtrain_epoch_loss\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_param = {\n",
    "    \"model\": faster_rcnn,\n",
    "    \"train_loader\": train_dataloader, \n",
    "    \"val_loader\": val_dataloader,\n",
    "    \"optimizer\": optimizer, \n",
    "    \"epochs\": total_epoch,\n",
    "    \"device\": device,\n",
    "    \"checkpoint_path\": './model/model_1', \n",
    "    \"load_checkpoint\": None\n",
    "}\n",
    "training_loss, validation_loss = train_model(**training_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5ca350f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66589e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'labels': tensor([1, 1, 1, 1, 1]),\n",
       " 'boxes': tensor([[214.7900,  98.5600, 367.1800, 333.6000],\n",
       "         [150.1100, 118.7800, 276.2100, 328.9300],\n",
       "         [ 53.7400, 132.5900,  72.0700, 192.5100],\n",
       "         [ 32.0300, 139.2700,  47.7700, 184.5300],\n",
       "         [ 15.3200, 138.2400,  28.2500, 186.9900]])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "randindx = random.randint(0, len(train_interface))\n",
    "idx, X, y = train_interface[randindx]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93954973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__bgr__', 'person', 'car']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_interface.target_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e05d3a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: '__bgr__', 1: 'person', 3: 'car'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_interface.idx_to_class"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ailab] *",
   "language": "python",
   "name": "conda-env-ailab-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
