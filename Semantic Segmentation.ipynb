{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "820c637c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Semantic Segmentation on CityScapes Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0954a96a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bac95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from PIL import Image\n",
    "\n",
    "import CityScapes_labels as labels\n",
    "from CityScapes import CityScapesInterface\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils import data\n",
    "from torchvision import transforms as transforms\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.segmentation import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f9d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check GPU\n",
    "device = torch.device('cpu')\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11552105",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Dataset Interface and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b5e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = '/mnt/data/course/psarin/inm705' # path to data\n",
    "list_of_classes = ['__bgr__', 'car', 'person'] # list of classes we wont to classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575366b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_interface_params = {\n",
    "    'data_root': data_root,\n",
    "    'list_of_classes': list_of_classes,\n",
    "    'labels': labels,\n",
    "    'phase': 'train',\n",
    "    'task': 'semantic'\n",
    "}\n",
    "\n",
    "val_interface_params = {\n",
    "    'data_root': data_root,\n",
    "    'list_of_classes': list_of_classes,\n",
    "    'labels': labels,\n",
    "    'phase': 'val',\n",
    "    'task': 'semantic'\n",
    "}\n",
    "\n",
    "test_interface_params = {\n",
    "    'data_root': data_root,\n",
    "    'list_of_classes': list_of_classes,\n",
    "    'labels': labels,\n",
    "    'phase': 'test',\n",
    "    'task': 'semantic'\n",
    "}\n",
    "\n",
    "train_interface = CityScapesInterface(**train_interface_params) # train data\n",
    "val_interface = CityScapesInterface(**val_interface_params) # validation data\n",
    "test_interface = CityScapesInterface(**test_interface_params) # test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aff788",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(train_interface, batch_size=1, shuffle=True)\n",
    "val_dataloader = data.DataLoader(val_interface, batch_size=1, shuffle=False)\n",
    "test_dataloader = data.DataLoader(test_interface, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cc39dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx, X, y = next(iter(train_dataloader))\n",
    "img = train_interface.load_img(idx, transform=False)\n",
    "plt.imshow(img)\n",
    "plt.imshow(y['mask'].squeeze_(0), alpha=0.6)\n",
    "plt.title('Picture with Mask Appplied')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c230cb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Fully Connected Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadb5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcn_model = segmentation.fcn_resnet50(pretrained_backbone=False, pretrained=False, num_classes=3, aux_loss=True)\n",
    "fcn_model=fcn_model.to(device)\n",
    "print(fcn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d825e2fd-92f9-4c5c-bad0-582dd000c49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model weight\n",
    "#torch.save(fcn_model.state_dict(), './fcn_model_pretrained_mscoco.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56d7bc5-ba9c-4e20-a6db-e13cdb3a8f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model with pre-trained backbone\n",
    "fcn_model.load_state_dict(torch.load('./fcn_model_pretrained_backbone.pth'))\n",
    "fcn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca435f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, img_path):\n",
    "    model.eval()\n",
    "    im = Image.open(img_path)\n",
    "    t_ = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.457, 0.407],\n",
    "                    std=[0.229,0.224,0.225])])                    \n",
    "    img = t_(im)    \n",
    "    img.unsqueeze_(0)\n",
    "    if device == torch.device(\"cuda\"):\n",
    "        img = img.to(device)\n",
    "    # get the output from the model\n",
    "    fcn_model.eval()\n",
    "    output = model(img)['out']\n",
    "    out = output.argmax(1).squeeze_(0).detach().clone().cpu().numpy()\n",
    "    plt.imshow(im)\n",
    "    plt.imshow(out, alpha=0.6)\n",
    "    plt.title('Picture with Mask Appplied')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    print(np.unique(out)[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0505d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(fcn_model, 'dogcat.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5169ea91-bb43-4235-a6e5-24a6727d10ae",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bacb54e-ab26-4c0d-aff5-66b6b5ac4bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# move model to cuda\n",
    "if device == torch.device('cuda'):\n",
    "    fcn_model = fcn_model.to(device)\n",
    "\n",
    "fcn_model.train() # train mode    \n",
    "# optimizer\n",
    "opt_pars = {'lr':1e-5, 'weight_decay':1e-3}\n",
    "optimizer = torch.optim.Adam(list(fcn_model.parameters()),**opt_pars)\n",
    "total_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d45895-c4ac-4e5e-8194-ff468d731ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load(\"./checkpoints/model.pt\")\n",
    "fcn_model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec200c0e-98a1-41cb-a7d4-f4580cd818d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "m = nn.LogSoftmax(dim=1)\n",
    "loss_function = nn.NLLLoss()\n",
    "\n",
    "for e in range(total_epochs):\n",
    "    epoch_loss = 0\n",
    "    start_time = time.time()\n",
    "    fcn_model.train()\n",
    "    for id, batch in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()\n",
    "        idx, X, y = batch\n",
    "        if device == torch.device('cuda'):\n",
    "            X, y['mask'] = X.to(device), y['mask'].to(device)\n",
    "            # list of images\n",
    "            #images = [im for im in X]\n",
    "            targets = []\n",
    "            lab={}\n",
    "            lab['mask'] = y['mask'].squeeze_(0)        \n",
    "            targets.append(lab)\n",
    "            # avoid empty objects\n",
    "        if len(targets)>0:\n",
    "            output = fcn_model(X)['out']\n",
    "            loss = loss_function(m(output), targets[0]['mask'].unsqueeze(0).long())\n",
    "            print('Loss: ', loss.item())         \n",
    "            epoch_loss += loss.item()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    epoch_loss = epoch_loss/len(train_dataloader)\n",
    "    epoch_time = (time.time() - start_time) /60**1\n",
    "    \n",
    "    torch.save({\n",
    "                'epoch': e,\n",
    "                'model_state_dict': fcn_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': epoch_loss,\n",
    "                }, \"./checkpoints/semantic_segmentation_v0.pt\")\n",
    "    \n",
    "    print(\"Loss = {0:.4f} in epoch {1:d}. Time: {2:d}\".format(epoch_loss, e, epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e3a0e1-70e7-4b4d-9001-275e42639cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = '/mnt/data/course/psarin/inm705/leftImg8bit/train/aachen/aachen_000003_000019_leftImg8bit.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cdf180-51e7-4b38-9330-6ad2d04acac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(fcn_model, img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58a865-1328-4086-88b8-50ffd3ffa48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 0\n",
    "PATH = \"./checkpoints/model.pt\"\n",
    "LOSS = loss.item()\n",
    "\n",
    "torch.save({\n",
    "            'epoch': EPOCH,\n",
    "            'model_state_dict': fcn_model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': LOSS,\n",
    "            }, PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
